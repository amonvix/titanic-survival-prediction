Titanic Survival Prediction ğŸ§ âš™ï¸



ğŸš€ How We Ship â€“ CI/CD Overview

This project follows a hybrid delivery strategy:

Continuous Integration (CI): Automatic
Continuous Deployment (CD): Manual (AWS ECS)

The goal is to ensure every commit is validated and packaged automatically,
while production releases remain under human control.

ğŸ§© Workflow Summary
Stage	Trigger	Description
CI (Build & Test)	Every push / PR to main or develop	Runs Ruff linting, Pytest, builds the Docker image, and publishes it to GitHub Container Registry (GHCR).
CD (Deploy)	Manual (â€œRun workflowâ€ in GitHub Actions)	Updates the running AWS ECS service to use a specific image version (tag).
Infra (Terraform)	Optional manual workflow	Applies or plans infrastructure changes with Terraform using OIDC authentication.
âš™ï¸ CI Pipeline (.github/workflows/ci.yml)

Trigger:
Runs on every push or pull_request.

Steps:

Lint & format check with Ruff

Unit testing with Pytest

Build Docker image

Push image to GHCR using commit SHA as tag

Output image tag for later deployment

Resulting image:

ghcr.io/Amonvix/titanic-survival-prediction/titanic:<GIT_SHA>

ğŸš€ CD Pipeline (.github/workflows/deploy-aws.yml)

Trigger:
Manual (GitHub Actions â†’ â€œDeploy to AWS ECS (manual)â€ â†’ â€œRun workflowâ€).

Inputs:

image_tag: SHA from the CI pipeline

environment: staging or production

Workflow Steps:

Authenticates with AWS using OIDC (no access keys needed)

Pulls the latest ECS task definition

Creates a new revision with the updated image

Updates ECS service and waits until it becomes stable

Production deployments can be gated with required approvals using GitHub Environments.

ğŸ“‚ Project Structure
titanic-survival-prediction/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ core/config.py
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ predict.py
â”‚   â”‚   â””â”€â”€ schemas.py
â”‚   â””â”€â”€ routers/main.py
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ titanic.csv
â”‚   â””â”€â”€ titanic_clean.csv
â”‚
â”œâ”€â”€ infra/
â”‚   â””â”€â”€ terraform/
â”‚       â”œâ”€â”€ main.tf
â”‚       â”œâ”€â”€ outputs.tf
â”‚       â””â”€â”€ provider.tf
â”‚
â”œâ”€â”€ models/pipeline.pkl
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ create_pipeline.py
â”‚   â”œâ”€â”€ save_sklearn_model.py
â”‚   â””â”€â”€ train_model.py
â”‚
â”œâ”€â”€ aws-oidc-setup/
â”‚   â”œâ”€â”€ policy-ecr.json
â”‚   â””â”€â”€ trust-policy.json
â”‚
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ requirements-dev.txt
â”œâ”€â”€ mypy.ini
â”œâ”€â”€ pytest.ini
â””â”€â”€ .github/workflows/ci.yml

ğŸ§± Infrastructure

Terraform defines all infrastructure resources (ECR, ECS, networking, IAM roles).
You can apply manually via a separate workflow:

Actions â†’ Infra (Terraform)


or locally:

cd infra/terraform
terraform init
terraform plan
terraform apply

ğŸ§¾ Example Request
curl -X POST http://localhost:8000/predict/ \
  -H "Content-Type: application/json" \
  -d '{
        "age": 28,
        "sex": "male",
        "pclass": 3,
        "sibsp": 0,
        "parch": 0,
        "fare": 7.25,
        "embarked": "Southampton",
        "deck": "Unknown"
      }'


Response:

{
  "survived_probability": 0.237,
  "survived": false
}

ğŸ” Required GitHub Secrets
Secret	Purpose
AWS_ROLE_TO_ASSUME	ARN of IAM Role trusted for GitHub OIDC
AWS_REGION	Region for ECS deployment
ECS_CLUSTER	ECS cluster name
ECS_SERVICE	ECS service name
ECS_TASK_FAMILY	Task definition family
ECS_CONTAINER_NAME	Container name in the ECS task
(optional) FLY_API_TOKEN	Kept for Fly.io testing or future lightweight deploys
ğŸ§­ Workflow Logic
flowchart LR
    subgraph CI["CI (Automatic)"]
        Lint[Ruff Lint]
        Test[Pytest]
        Build[Docker Build]
        Push[Push to GHCR]
    end

    subgraph CD["CD (Manual)"]
        Deploy[Deploy via ECS Update]
        Wait[Wait for Service Stability]
    end

    Lint --> Test --> Build --> Push --> Deploy --> Wait

ğŸ§© Benefits

âœ… Strong quality gate (every commit tested and linted)
âœ… Immutable image versioning (tag = commit SHA)
âœ… Secure AWS access via OIDC (no static keys)
âœ… Manual approval before production deployment
âœ… Simple rollback â€” redeploy previous SHA

ğŸ§  TL;DR

We build automatically. We deploy deliberately.
This gives the team speed in development and confidence in production.

ğŸ“¦ Next Steps

Add coverage reporting

Automate rollback on failure

Integrate Prometheus/Grafana for metrics

Add Terraform remote backend (S3 + DynamoDB)

ğŸ§‘â€ğŸ’» Author

Daniel Pedroso (Amonvix)
GitHub
 â€¢ LinkedIn

ğŸ“œ License

Licensed under the MIT License.
Built with passion and precision ğŸ§©